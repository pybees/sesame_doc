{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute SESAME inverse solution on evoked data\n\n\nIn this example we shall apply SESAME on an evoked dataset,\ncorresponding to the response to an auditory stimulus. Data are taken from the MNE-Python\n`sample <https://mne.tools/stable/generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path>`_\ndataset.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "# Authors: Gianvittorio Luria <luria@dima.unige.it>\n#          Sara Sommariva <sommariva@dima.unige.it>\n#          Alberto Sorrentino <sorrentino@dima.unige.it>\n#\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 3\n\nfrom os import path as op\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mayavi import mlab\n\nfrom mne.datasets import sample\nfrom mne import read_forward_solution, pick_types_forward, read_evokeds\nfrom mne.label import _n_colors\n\nfrom sesameeg import Sesame\n\n\ndata_path = sample.data_path()\nsubject = 'sample'\nsubjects_dir = op.join(data_path, 'subjects')\nfname_fwd = op.join(data_path, 'MEG', subject,\n                    'sample_audvis-meg-eeg-oct-6-fwd.fif')\nfname_evoked = op.join(data_path, 'MEG', subject, 'sample_audvis-ave.fif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the forward solution  $\\textbf{G}$  and the evoked data\n$\\textbf{y}$.\nThe forward solution also defines the employed brain discretization.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "meg_sensor_type = True  # All MEG sensors will be included\neeg_sensor_type = False\n\n# Forward solution\nfwd = read_forward_solution(fname_fwd, exclude='bads')\nfwd = pick_types_forward(fwd, meg=meg_sensor_type,\n                         eeg=eeg_sensor_type, ref_meg=False)\n\n# Evoked Data\ncondition = 'Left Auditory'\nevoked = read_evokeds(fname_evoked, condition=condition, baseline=(None, 0))\nevoked = evoked.pick_types(meg=meg_sensor_type,\n                           eeg=eeg_sensor_type, exclude='bads')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the parameters.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "time_min, time_max = 0.045, 0.135  # Select N100m\nsubsample = None\nsample_min, sample_max = evoked.time_as_index([time_min, time_max],\n                                              use_rounding=True)\n\n# To accelerate the run time of this example, we use a small number of\n# particles. We recall that the parameter ``n_parts`` represents, roughly speaking,\n# the number of candidate solutions that are tested in the Monte Carlo procedure;\n# larger values yield in principle more accurate reconstructions but also entail a\n# higher computational cost. Setting the value to about a hundred seems to represent\n# a good trade\u2013off.\nn_parts = 10\n# If None, noise_std and dip_mom_std will be estimated by SESAME.\nnoise_std = None\ndip_mom_std = None\n\n\nnoise_cov = None\n# You can make SESAME pre-whiten the data by providing a noise covariance\n# from mne import read_cov\n# fname_cov = op.join(sample.data_path(), 'MEG', subject,\n#                    'sample_audvis-cov.fif')\n# noise_cov = read_cov(fname_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the selected data.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "fig = evoked.plot(show=False)\nfor ax in fig.get_axes():\n    ax.axvline(time_min, color='r', linewidth=2.0)\n    ax.axvline(time_max, color='r', linewidth=2.0)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply SESAME.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "_sesame = Sesame(fwd, evoked, n_parts=n_parts, noise_std=noise_std,\n                 top_min=time_min, top_max=time_max, dip_mom_std=dip_mom_std,\n                 hyper_q=True, noise_cov=noise_cov, subsample=subsample)\n_sesame.apply_sesame()\n\nprint('    Estimated number of sources: {0}'.format(_sesame.est_n_dips[-1]))\nprint('    Estimated source locations: {0}'.format(_sesame.est_locs[-1]))\n\n# Compute goodness of fit\ngof = _sesame.goodness_of_fit()\nprint('    Goodness of fit with the recorded data: {0}%'.format(round(gof, 4) * 100))\n\n# Compute source dispersion\nsd = _sesame.source_dispersion()\nprint('    Source Dispersion: {0} mm'.format(round(sd, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the amplitude of the estimated sources as function of time.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "est_n_dips = _sesame.est_n_dips[-1]\nest_locs = _sesame.est_locs[-1]\n\ntimes = evoked.times[_sesame.s_min:_sesame.s_max+1]\namplitude = np.array([np.linalg.norm(_sesame.est_dip_moms[:, 3*i_d:3 * (i_d + 1)],\n                                     axis=1) for i_d in range(est_n_dips)])\ncolors = _n_colors(est_n_dips)\nplt.figure()\nfor idx, amp in enumerate(amplitude):\n    plt.plot(1e3*times, 1e9*amp, color=colors[idx], linewidth=2)\nplt.xlabel('Time (ms)')\nplt.ylabel('Source amplitude (nAm)')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the posterior map of the dipoles' location\n$p(r| \\textbf{y}, 2)$ and the estimated sources on the inflated brain.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "stc = _sesame.compute_stc(subject)\nclim = dict(kind='value', lims=[1e-4, 1e-1, 1])\nbrain = stc.plot(subject, surface='inflated', hemi='split', clim=clim,\n                 time_label=' ', subjects_dir=subjects_dir, size=(1000, 600))\nnv_lh = stc.vertices[0].shape[0]\nfor idx, loc in enumerate(est_locs):\n    if loc < nv_lh:\n        brain.add_foci(stc.vertices[0][loc], coords_as_verts=True,\n                       hemi='lh', color=colors[idx], scale_factor=0.3)\n    else:\n        brain.add_foci(stc.vertices[1][loc-nv_lh], coords_as_verts=True,\n                       hemi='rh', color=colors[idx], scale_factor=0.3)\n\nmlab.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save results.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "# You can save SESAME result in an HDF5 file with:\n# _sesame.save_h5(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)\n\n# You can save SESAME result in a Pickle file with:\n# _sesame.save_pkl(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)"
      ]
    }
  ],
  "nbformat": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "version": "3.5.2",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "name": "python",
      "mimetype": "text/x-python"
    }
  },
  "nbformat_minor": 0
}